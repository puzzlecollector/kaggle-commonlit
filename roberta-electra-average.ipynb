{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import * \nimport numpy as np \nimport pandas as pd\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \nimport time \nimport datetime \nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport re\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-23T09:05:25.322607Z","iopub.execute_input":"2021-07-23T09:05:25.322949Z","iopub.status.idle":"2021-07-23T09:05:33.123787Z","shell.execute_reply.started":"2021-07-23T09:05:25.322873Z","shell.execute_reply":"2021-07-23T09:05:33.122855Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n  '\"sox\" backend is being deprecated. '\n","output_type":"stream"}]},{"cell_type":"code","source":"roberta_checkpoint = torch.load(\"../input/roberta-large-epoch-9/RoBERTa_large_9\")\nelectra_checkpoint = torch.load(\"../input/electra-largeepoch6/ELECTRA_large_6\") \n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:07:36.488152Z","iopub.execute_input":"2021-07-23T09:07:36.488492Z","iopub.status.idle":"2021-07-23T09:07:46.560243Z","shell.execute_reply.started":"2021-07-23T09:07:36.488463Z","shell.execute_reply":"2021-07-23T09:07:46.559239Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"roberta_test = RobertaForSequenceClassification.from_pretrained(\"../input/huggingface-roberta/roberta-large\", num_labels=1) \nroberta_test.load_state_dict(roberta_checkpoint)\nroberta_test.cuda()\nprint()","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:08:15.038313Z","iopub.execute_input":"2021-07-23T09:08:15.038634Z","iopub.status.idle":"2021-07-23T09:08:31.514901Z","shell.execute_reply.started":"2021-07-23T09:08:15.038604Z","shell.execute_reply":"2021-07-23T09:08:31.513797Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/huggingface-roberta/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../input/huggingface-roberta/roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"electra_test = ElectraForSequenceClassification.from_pretrained(\"../input/electra/large-discriminator\", num_labels=1) \nelectra_test.load_state_dict(electra_checkpoint) \nelectra_test.cuda() \nprint() ","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:09:08.451589Z","iopub.execute_input":"2021-07-23T09:09:08.451988Z","iopub.status.idle":"2021-07-23T09:09:25.041384Z","shell.execute_reply.started":"2021-07-23T09:09:08.451955Z","shell.execute_reply":"2021-07-23T09:09:25.040434Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at ../input/electra/large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ../input/electra/large-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"roberta_tokenizer = RobertaTokenizerFast.from_pretrained(\"../input/huggingface-roberta/roberta-large\") \n\ndef roberta_tokenizer_process(sent, MAX_LEN):  \n    encoded_dict = roberta_tokenizer.encode_plus(\n        text = sent, \n        add_special_tokens = True, \n        pad_to_max_length = False, \n        return_attention_mask = True \n    )\n    input_id = encoded_dict['input_ids'] \n    attention_mask = encoded_dict['attention_mask'] \n    if len(input_id) > 512: \n        input_id = input_id[:129] + input_id[-383:] \n        attention_mask = attention_maks[:129] + attention_mask[-383:] \n        print(\"Long Text!! Using Head+Tail Truncation\") \n    elif len(input_id) <= 512: \n        input_id = input_id + [0]*(512 - len(input_id)) \n        attention_mask = attention_mask + [0]*(512-len(attention_mask)) \n        \n    return input_id, attention_mask\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:14:27.061338Z","iopub.execute_input":"2021-07-23T09:14:27.061656Z","iopub.status.idle":"2021-07-23T09:14:27.152001Z","shell.execute_reply.started":"2021-07-23T09:14:27.061626Z","shell.execute_reply":"2021-07-23T09:14:27.151126Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"electra_tokenizer = ElectraTokenizer.from_pretrained(\"../input/electra/large-discriminator\") \n\ndef electra_tokenizer_process(sent, MAX_LEN):  \n    encoded_dict = electra_tokenizer.encode_plus(\n        text = sent, \n        add_special_tokens = True, \n        pad_to_max_length = False, \n        return_attention_mask = True \n    )\n    input_id = encoded_dict['input_ids'] \n    attention_mask = encoded_dict['attention_mask'] \n    if len(input_id) > 512: \n        input_id = input_id[:129] + input_id[-383:] \n        attention_mask = attention_maks[:129] + attention_mask[-383:] \n        print(\"Long Text!! Using Head+Tail Truncation\") \n    elif len(input_id) <= 512: \n        input_id = input_id + [0]*(512 - len(input_id)) \n        attention_mask = attention_mask + [0]*(512-len(attention_mask)) \n        \n    return input_id, attention_mask","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:14:31.063585Z","iopub.execute_input":"2021-07-23T09:14:31.064070Z","iopub.status.idle":"2021-07-23T09:14:31.108552Z","shell.execute_reply.started":"2021-07-23T09:14:31.064031Z","shell.execute_reply":"2021-07-23T09:14:31.107754Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nNUM_EPOCHS = 10 \nVALID_SPLIT = 0.1 \nMAX_LEN = 512\n\n\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\") \nsubmission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\n\ndevice = torch.device(\"cuda\")\n\n\ntest_texts = test['excerpt'].values \n\nroberta_predictions = [] \n\nfor text in tqdm(test_texts, position=0,leave=True): \n    input_id, attention_mask = roberta_tokenizer_process(text, MAX_LEN=MAX_LEN) \n    input_id = torch.tensor(input_id, dtype=int) \n    attention_mask = torch.tensor(attention_mask, dtype=int) \n    \n    input_id = torch.reshape(input_id, (-1,MAX_LEN)) \n    attention_mask = torch.reshape(attention_mask, (-1,MAX_LEN)) \n    \n    input_id = input_id.to(device) \n    attention_mask = attention_mask.to(device) \n    \n    with torch.no_grad(): \n            outputs = roberta_test(input_id, \n                                   token_type_ids=None, \n                                   attention_mask=attention_mask) \n    \n    yhat = outputs[0].item() \n    roberta_predictions.append(yhat)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:14:34.078294Z","iopub.execute_input":"2021-07-23T09:14:34.078727Z","iopub.status.idle":"2021-07-23T09:14:35.454249Z","shell.execute_reply.started":"2021-07-23T09:14:34.078660Z","shell.execute_reply":"2021-07-23T09:14:35.453278Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:01<00:00,  5.16it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"electra_predictions = [] \n\nfor text in tqdm(test_texts, position=0,leave=True): \n    input_id, attention_mask = electra_tokenizer_process(text, MAX_LEN=MAX_LEN) \n    input_id = torch.tensor(input_id, dtype=int) \n    attention_mask = torch.tensor(attention_mask, dtype=int) \n    \n    input_id = torch.reshape(input_id, (-1,MAX_LEN)) \n    attention_mask = torch.reshape(attention_mask, (-1,MAX_LEN)) \n    \n    input_id = input_id.to(device) \n    attention_mask = attention_mask.to(device) \n    \n    with torch.no_grad(): \n            outputs = electra_test(input_id, \n                                   token_type_ids=None, \n                                   attention_mask=attention_mask) \n    \n    yhat = outputs[0].item() \n    electra_predictions.append(yhat)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:15:27.471272Z","iopub.execute_input":"2021-07-23T09:15:27.471600Z","iopub.status.idle":"2021-07-23T09:15:28.024778Z","shell.execute_reply.started":"2021-07-23T09:15:27.471571Z","shell.execute_reply":"2021-07-23T09:15:28.023800Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"100%|██████████| 7/7 [00:00<00:00, 12.91it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"roberta_predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:15:31.143797Z","iopub.execute_input":"2021-07-23T09:15:31.144161Z","iopub.status.idle":"2021-07-23T09:15:31.155576Z","shell.execute_reply.started":"2021-07-23T09:15:31.144130Z","shell.execute_reply":"2021-07-23T09:15:31.154719Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[0.1232486218214035,\n -0.3321461081504822,\n -0.38081932067871094,\n -1.8343415260314941,\n -1.7079259157180786,\n -0.8954422473907471,\n 0.4654872417449951]"},"metadata":{}}]},{"cell_type":"code","source":"electra_predictions","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:15:35.267166Z","iopub.execute_input":"2021-07-23T09:15:35.267484Z","iopub.status.idle":"2021-07-23T09:15:35.273022Z","shell.execute_reply.started":"2021-07-23T09:15:35.267453Z","shell.execute_reply":"2021-07-23T09:15:35.271958Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[-0.07344838976860046,\n -0.265074223279953,\n -0.36824485659599304,\n -2.005181312561035,\n -1.8369956016540527,\n -0.8404904007911682,\n -0.0658130794763565]"},"metadata":{}}]},{"cell_type":"code","source":"avg_predictions = (np.array(roberta_predictions) + np.array(electra_predictions)) / 2.0 ","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:16:09.616801Z","iopub.execute_input":"2021-07-23T09:16:09.617166Z","iopub.status.idle":"2021-07-23T09:16:09.622051Z","shell.execute_reply.started":"2021-07-23T09:16:09.617135Z","shell.execute_reply":"2021-07-23T09:16:09.620804Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"submission.iloc[:,1] = avg_predictions \n\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:16:44.550873Z","iopub.execute_input":"2021-07-23T09:16:44.551196Z","iopub.status.idle":"2021-07-23T09:16:44.572283Z","shell.execute_reply.started":"2021-07-23T09:16:44.551166Z","shell.execute_reply":"2021-07-23T09:16:44.571320Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"          id    target\n0  c0f722661  0.024900\n1  f0953f0a5 -0.298610\n2  0df072751 -0.374532\n3  04caf4e0c -1.919761\n4  0e63f8bea -1.772461\n5  12537fe78 -0.867966\n6  965e592c0  0.199837","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c0f722661</td>\n      <td>0.024900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f0953f0a5</td>\n      <td>-0.298610</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0df072751</td>\n      <td>-0.374532</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04caf4e0c</td>\n      <td>-1.919761</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0e63f8bea</td>\n      <td>-1.772461</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>12537fe78</td>\n      <td>-0.867966</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>965e592c0</td>\n      <td>0.199837</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T09:16:56.621152Z","iopub.execute_input":"2021-07-23T09:16:56.621486Z","iopub.status.idle":"2021-07-23T09:16:56.629584Z","shell.execute_reply.started":"2021-07-23T09:16:56.621456Z","shell.execute_reply":"2021-07-23T09:16:56.628799Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}